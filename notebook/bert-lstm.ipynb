{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12008326,"sourceType":"datasetVersion","datasetId":7554561}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers torch scikit-learn pandas","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T10:44:10.448438Z","iopub.execute_input":"2025-06-12T10:44:10.448742Z","iopub.status.idle":"2025-06-12T10:45:23.891384Z","shell.execute_reply.started":"2025-06-12T10:44:10.448718Z","shell.execute_reply":"2025-06-12T10:45:23.890667Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom transformers import BertTokenizer, BertModel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm import tqdm\n\n# Cáº¥u hÃ¬nh thiáº¿t bá»‹\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T10:45:23.893011Z","iopub.execute_input":"2025-06-12T10:45:23.893245Z","iopub.status.idle":"2025-06-12T10:45:47.957342Z","shell.execute_reply.started":"2025-06-12T10:45:23.893222Z","shell.execute_reply":"2025-06-12T10:45:47.956565Z"}},"outputs":[{"name":"stderr","text":"2025-06-12 10:45:35.461519: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749725135.678024      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749725135.743980      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/tiktok-comments/tiktok_comments_balanced.csv\")\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T10:45:47.958201Z","iopub.execute_input":"2025-06-12T10:45:47.958804Z","iopub.status.idle":"2025-06-12T10:45:48.024568Z","shell.execute_reply.started":"2025-06-12T10:45:47.958780Z","shell.execute_reply":"2025-06-12T10:45:48.023943Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   line_number                                               text  \\\n0         2679                                            sá»£ tháº­t   \n1        26129               á»‘i dá»“i Ã´i fpt shop chÃ¡y tá»›i Ä‘Ã³ má»‡t_Ã¡   \n2        20113                       xem mÃ  khÃ³c thÆ°Æ¡ng_k chá»‹u dc   \n3        17380               Ä‘Ã n_bÃ  sá»‘ng thá» hÆ¡n Ä‘Ã n_Ã´ng lÃ  váº­y k   \n4        18200  cÃ´ áº¥y giÃ  Ä‘i nhiá»u quÃ¡ váº«n nhá»› áº£nh chá»¥p cÃ´ lÃºc...   \n\n   emotion_label  \n0              3  \n1              2  \n2              2  \n3              0  \n4              2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>line_number</th>\n      <th>text</th>\n      <th>emotion_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2679</td>\n      <td>sá»£ tháº­t</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>26129</td>\n      <td>á»‘i dá»“i Ã´i fpt shop chÃ¡y tá»›i Ä‘Ã³ má»‡t_Ã¡</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20113</td>\n      <td>xem mÃ  khÃ³c thÆ°Æ¡ng_k chá»‹u dc</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17380</td>\n      <td>Ä‘Ã n_bÃ  sá»‘ng thá» hÆ¡n Ä‘Ã n_Ã´ng lÃ  váº­y k</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18200</td>\n      <td>cÃ´ áº¥y giÃ  Ä‘i nhiá»u quÃ¡ váº«n nhá»› áº£nh chá»¥p cÃ´ lÃºc...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"label_mapping = {\n    0: \"Vui váº»\",        # tÃ­ch cá»±c\n    1: \"Tá»©c giáº­n\",      # negative (giáº­n dá»¯, bá»±c tá»©c)\n    2: \"Buá»“n\",          # sadness\n    3: \"Sá»£ hÃ£i\",        # lo láº¯ng, hoáº£ng loáº¡n\n    4: \"Trung láº­p\"      # neutral\n}\ndf[\"label_text\"] = df[\"emotion_label\"].map(label_mapping)\n\nle = LabelEncoder()\ndf['label'] = le.fit_transform(df['label_text'])\nnum_classes = len(le.classes_)\n\n\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T10:45:48.025943Z","iopub.execute_input":"2025-06-12T10:45:48.026133Z","iopub.status.idle":"2025-06-12T10:45:48.049739Z","shell.execute_reply.started":"2025-06-12T10:45:48.026119Z","shell.execute_reply":"2025-06-12T10:45:48.049196Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"       line_number                                               text  \\\n0             2679                                            sá»£ tháº­t   \n1            26129               á»‘i dá»“i Ã´i fpt shop chÃ¡y tá»›i Ä‘Ã³ má»‡t_Ã¡   \n2            20113                       xem mÃ  khÃ³c thÆ°Æ¡ng_k chá»‹u dc   \n3            17380               Ä‘Ã n_bÃ  sá»‘ng thá» hÆ¡n Ä‘Ã n_Ã´ng lÃ  váº­y k   \n4            18200  cÃ´ áº¥y giÃ  Ä‘i nhiá»u quÃ¡ váº«n nhá»› áº£nh chá»¥p cÃ´ lÃºc...   \n...            ...                                                ...   \n14448        26549                                        nhÃ¬n sá»£ tháº¿   \n14449        19664                          khá»• thÃ¢n hai nhÃ  bÃªn cáº¡nh   \n14450        27967                                      hÃ£i lun vk Æ¡i   \n14451         7682                                                 vÅ©   \n14452         6513                         tá»±_hÃ o lÃ  ngÆ°á»i_dÃ¢n cá»§ chi   \n\n       emotion_label label_text  label  \n0                  3     Sá»£ hÃ£i      1  \n1                  2       Buá»“n      0  \n2                  2       Buá»“n      0  \n3                  0     Vui váº»      4  \n4                  2       Buá»“n      0  \n...              ...        ...    ...  \n14448              3     Sá»£ hÃ£i      1  \n14449              2       Buá»“n      0  \n14450              3     Sá»£ hÃ£i      1  \n14451              4  Trung láº­p      2  \n14452              0     Vui váº»      4  \n\n[14453 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>line_number</th>\n      <th>text</th>\n      <th>emotion_label</th>\n      <th>label_text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2679</td>\n      <td>sá»£ tháº­t</td>\n      <td>3</td>\n      <td>Sá»£ hÃ£i</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>26129</td>\n      <td>á»‘i dá»“i Ã´i fpt shop chÃ¡y tá»›i Ä‘Ã³ má»‡t_Ã¡</td>\n      <td>2</td>\n      <td>Buá»“n</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20113</td>\n      <td>xem mÃ  khÃ³c thÆ°Æ¡ng_k chá»‹u dc</td>\n      <td>2</td>\n      <td>Buá»“n</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17380</td>\n      <td>Ä‘Ã n_bÃ  sá»‘ng thá» hÆ¡n Ä‘Ã n_Ã´ng lÃ  váº­y k</td>\n      <td>0</td>\n      <td>Vui váº»</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18200</td>\n      <td>cÃ´ áº¥y giÃ  Ä‘i nhiá»u quÃ¡ váº«n nhá»› áº£nh chá»¥p cÃ´ lÃºc...</td>\n      <td>2</td>\n      <td>Buá»“n</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14448</th>\n      <td>26549</td>\n      <td>nhÃ¬n sá»£ tháº¿</td>\n      <td>3</td>\n      <td>Sá»£ hÃ£i</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14449</th>\n      <td>19664</td>\n      <td>khá»• thÃ¢n hai nhÃ  bÃªn cáº¡nh</td>\n      <td>2</td>\n      <td>Buá»“n</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14450</th>\n      <td>27967</td>\n      <td>hÃ£i lun vk Æ¡i</td>\n      <td>3</td>\n      <td>Sá»£ hÃ£i</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14451</th>\n      <td>7682</td>\n      <td>vÅ©</td>\n      <td>4</td>\n      <td>Trung láº­p</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>14452</th>\n      <td>6513</td>\n      <td>tá»±_hÃ o lÃ  ngÆ°á»i_dÃ¢n cá»§ chi</td>\n      <td>0</td>\n      <td>Vui váº»</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>14453 rows Ã— 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Chia dá»¯ liá»‡u\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    df['text'], df['label'], test_size=0.2, stratify=df['label'], random_state=42\n)\n\n# Tokenizer\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\nMAX_LEN = 64\n\ndef tokenize(texts):\n    input_ids, attention_masks = [], []\n    for text in texts:\n        encoded = tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=MAX_LEN,\n            truncation=True,\n            padding='max_length',\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n        input_ids.append(encoded['input_ids'])\n        attention_masks.append(encoded['attention_mask'])\n    return torch.cat(input_ids, dim=0), torch.cat(attention_masks, dim=0)\n\n# Token hÃ³a\ntrain_ids, train_masks = tokenize(train_texts.tolist())\nval_ids, val_masks = tokenize(val_texts.tolist())\n\ntrain_labels = torch.tensor(train_labels.tolist())\nval_labels = torch.tensor(val_labels.tolist())\n\n# DataLoader\ntrain_data = TensorDataset(train_ids, train_masks, train_labels)\nval_data = TensorDataset(val_ids, val_masks, val_labels)\n\ntrain_loader = DataLoader(train_data, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T10:45:48.050458Z","iopub.execute_input":"2025-06-12T10:45:48.050747Z","iopub.status.idle":"2025-06-12T10:45:53.176039Z","shell.execute_reply.started":"2025-06-12T10:45:48.050724Z","shell.execute_reply":"2025-06-12T10:45:53.175288Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bea26dd8e324f518018b7b09bc48f6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"572a4e0dbb9a4286a40464f77a44ee82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54ba8908ae4c447bafd4343dc837133c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"581dba0b61ad4c46888365ff6f831bd7"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Load BERT vÃ  LSTM\n\nclass BertLSTMClassifier(nn.Module):\n    def __init__(self, num_classes):\n        super(BertLSTMClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n        self.lstm = nn.LSTM(input_size=768, hidden_size=128, num_layers=1,\n                            batch_first=True, bidirectional=True)\n        self.dropout = nn.Dropout(0.3)\n        self.fc = nn.Linear(128 * 2, num_classes)\n\n    def forward(self, input_ids, attention_mask):\n        with torch.no_grad():\n            bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        lstm_out, _ = self.lstm(bert_output.last_hidden_state)\n        final_output = lstm_out[:, -1, :]\n        dropped = self.dropout(final_output)\n        logits = self.fc(dropped)\n        return logits\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T11:08:24.020143Z","iopub.execute_input":"2025-06-12T11:08:24.020501Z","iopub.status.idle":"2025-06-12T11:08:24.026223Z","shell.execute_reply.started":"2025-06-12T11:08:24.020478Z","shell.execute_reply":"2025-06-12T11:08:24.025600Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Huáº¥n luyá»‡n\nmodel = BertLSTMClassifier(num_classes).to(device)\noptimizer = optim.Adam(model.parameters(), lr=2e-4)\ncriterion = nn.CrossEntropyLoss()\n\nEPOCHS = 10\nfor epoch in range(EPOCHS):\n    lstm.train()\n    fc.train()\n    total_loss = 0\n\n    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n\n        with torch.no_grad():\n            bert_output = bert(input_ids=input_ids, attention_mask=attention_mask)\n        sequence_output = bert_output.last_hidden_state  # (B, T, 768)\n\n        lstm_out, _ = lstm(sequence_output)\n        final_output = lstm_out[:, -1, :]\n        dropped = dropout(final_output)\n        logits = fc(dropped)\n\n        loss = criterion(logits, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch+1} - Loss: {total_loss/len(train_loader):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T11:08:27.695640Z","iopub.execute_input":"2025-06-12T11:08:27.696174Z","iopub.status.idle":"2025-06-12T11:15:49.128745Z","shell.execute_reply.started":"2025-06-12T11:08:27.696153Z","shell.execute_reply":"2025-06-12T11:15:49.127788Z"}},"outputs":[{"name":"stderr","text":"Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 362/362 [00:38<00:00,  9.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 - Loss: 0.6511\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 362/362 [00:40<00:00,  8.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 - Loss: 0.6510\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 362/362 [00:42<00:00,  8.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 - Loss: 0.6524\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 362/362 [00:44<00:00,  8.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 - Loss: 0.6532\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 362/362 [00:45<00:00,  7.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 - Loss: 0.6515\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 362/362 [00:45<00:00,  7.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 - Loss: 0.6520\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 362/362 [00:45<00:00,  7.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 - Loss: 0.6508\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 362/362 [00:46<00:00,  7.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 - Loss: 0.6522\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 362/362 [00:46<00:00,  7.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 - Loss: 0.6497\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 362/362 [00:46<00:00,  7.85it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 10 - Loss: 0.6521\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"**ÄÃ¡nh giÃ¡**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport numpy as np\n\nlstm.eval()\nfc.eval()\n\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for batch in tqdm(val_loader, desc=\"ÄÃ¡nh giÃ¡\"):\n        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n\n        bert_output = bert(input_ids=input_ids, attention_mask=attention_mask)\n        sequence_output = bert_output.last_hidden_state\n\n        lstm_out, _ = lstm(sequence_output)\n        final_output = lstm_out[:, -1, :]\n        logits = fc(dropout(final_output))\n\n        preds = torch.argmax(logits, dim=1)\n\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n# ÄÃ¡nh giÃ¡\nacc = accuracy_score(all_labels, all_preds)\nprint(f\"\\nâœ… Accuracy: {acc:.4f}\\n\")\n\nprint(\"ğŸ“‹ Classification Report:\")\nprint(classification_report(all_labels, all_preds, target_names=le.classes_.astype(str)))\n\n# (Tuá»³ chá»n) Confusion Matrix\nprint(\"ğŸ“Š Confusion Matrix:\")\nprint(confusion_matrix(all_labels, all_preds))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T11:17:39.241280Z","iopub.execute_input":"2025-06-12T11:17:39.241585Z","iopub.status.idle":"2025-06-12T11:17:48.929231Z","shell.execute_reply.started":"2025-06-12T11:17:39.241566Z","shell.execute_reply":"2025-06-12T11:17:48.928363Z"}},"outputs":[{"name":"stderr","text":"ÄÃ¡nh giÃ¡: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:09<00:00,  9.41it/s]","output_type":"stream"},{"name":"stdout","text":"\nâœ… Accuracy: 0.5507\n\nğŸ“‹ Classification Report:\n              precision    recall  f1-score   support\n\n        Buá»“n       0.59      0.51      0.54       626\n      Sá»£ hÃ£i       0.65      0.70      0.67       551\n   Trung láº­p       0.57      0.54      0.55       551\n    Tá»©c giáº­n       0.50      0.59      0.54       611\n      Vui váº»       0.45      0.42      0.43       552\n\n    accuracy                           0.55      2891\n   macro avg       0.55      0.55      0.55      2891\nweighted avg       0.55      0.55      0.55      2891\n\nğŸ“Š Confusion Matrix:\n[[318  56  63 116  73]\n [ 38 387  26  78  22]\n [ 49  35 296  67 104]\n [ 58  71  38 361  83]\n [ 80  49  96  97 230]]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"Test model","metadata":{}},{"cell_type":"code","source":"def predict_sentiment(texts):\n    if isinstance(texts, str):\n        texts = [texts]\n\n    # Token hÃ³a\n    input_ids, attention_masks = tokenize(texts)\n    input_ids, attention_masks = input_ids.to(device), attention_masks.to(device)\n\n    # TrÃ­ch Ä‘áº·c trÆ°ng tá»« BERT\n    with torch.no_grad():\n        bert_output = bert(input_ids=input_ids, attention_mask=attention_masks)\n        sequence_output = bert_output.last_hidden_state\n\n        lstm_out, _ = lstm(sequence_output)\n        final_output = lstm_out[:, -1, :]\n        logits = fc(dropout(final_output))\n        preds = torch.argmax(logits, dim=1)\n\n    return le.inverse_transform(preds.cpu().numpy())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T11:18:01.695070Z","iopub.execute_input":"2025-06-12T11:18:01.695381Z","iopub.status.idle":"2025-06-12T11:18:01.700706Z","shell.execute_reply.started":"2025-06-12T11:18:01.695359Z","shell.execute_reply":"2025-06-12T11:18:01.700129Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"test_inputs = [\n    \"Tá»± nhiÃªn ra Ä‘Æ°á»ng cÃ¡i k Ä‘á»¥ng cháº¡m j ai cá»§ng sá»£ ngangğŸ˜‘\",\n    \"LÃºc Ä‘áº§u thÃ¬ \"\"TÃ¹ng BÃ² Ä‘Ã¢m, xong 1 lÃºc sau thÃ¬ \"\"vÃ o tÃ¹ nha\"\"ğŸ˜‚\",\n    \"báº¯t quÃ¡ nhanh ğŸ¥° CÃ´ng An Viá»‡t Nam mÃ¬nh quÃ¡ giá»i, xuáº¥t sáº¯c ğŸ¥°\"\n]\n\npredicted_labels = predict_sentiment(test_inputs)\n\nfor text, label in zip(test_inputs, predicted_labels):\n    print(f\"ğŸ“ \\\"{text}\\\" â†’ ğŸ’¬ Dá»± Ä‘oÃ¡n: {label}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T11:18:04.474866Z","iopub.execute_input":"2025-06-12T11:18:04.475653Z","iopub.status.idle":"2025-06-12T11:18:04.503394Z","shell.execute_reply.started":"2025-06-12T11:18:04.475622Z","shell.execute_reply":"2025-06-12T11:18:04.502701Z"}},"outputs":[{"name":"stdout","text":"ğŸ“ \"Tá»± nhiÃªn ra Ä‘Æ°á»ng cÃ¡i k Ä‘á»¥ng cháº¡m j ai cá»§ng sá»£ ngangğŸ˜‘\" â†’ ğŸ’¬ Dá»± Ä‘oÃ¡n: Sá»£ hÃ£i\nğŸ“ \"LÃºc Ä‘áº§u thÃ¬ TÃ¹ng BÃ² Ä‘Ã¢m, xong 1 lÃºc sau thÃ¬ vÃ o tÃ¹ nhağŸ˜‚\" â†’ ğŸ’¬ Dá»± Ä‘oÃ¡n: Vui váº»\nğŸ“ \"báº¯t quÃ¡ nhanh ğŸ¥° CÃ´ng An Viá»‡t Nam mÃ¬nh quÃ¡ giá»i, xuáº¥t sáº¯c ğŸ¥°\" â†’ ğŸ’¬ Dá»± Ä‘oÃ¡n: Vui váº»\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import zipfile\ntorch.save(model, \"bert_lstm_full_model.pt\")\n\n\nwith zipfile.ZipFile(\"bert_lstm_model.zip\", \"w\") as zipf:\n    zipf.write(\"bert_lstm_full_model.pt\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T11:26:30.138672Z","iopub.execute_input":"2025-06-12T11:26:30.139403Z","iopub.status.idle":"2025-06-12T11:26:34.315626Z","shell.execute_reply.started":"2025-06-12T11:26:30.139374Z","shell.execute_reply":"2025-06-12T11:26:34.314731Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"from transformers import BertTokenizer\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n\nmodel = torch.load(\"/kaggle/working/bert_lstm_full_model.pt\", map_location=device, weights_only=False)\nmodel.eval()\n\ntext = \"Tá»± nhiÃªn ra Ä‘Æ°á»ng cÃ¡i k Ä‘á»¥ng cháº¡m j ai cá»§ng sá»£ ngangğŸ˜‘\"\n\nencoded = tokenizer.encode_plus(\n    text,\n    add_special_tokens=True,\n    max_length=64,\n    truncation=True,\n    padding='max_length',\n    return_attention_mask=True,\n    return_tensors='pt'\n)\n\ninput_ids = encoded['input_ids'].to(device)\nattention_mask = encoded['attention_mask'].to(device)\n\n\nwith torch.no_grad():\n    logits = model(input_ids, attention_mask)\n    pred = torch.argmax(logits, dim=1).item()\n\nprint(\"âœ… MÃ£ lá»›p dá»± Ä‘oÃ¡n:\", pred)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T11:27:31.633087Z","iopub.execute_input":"2025-06-12T11:27:31.633406Z","iopub.status.idle":"2025-06-12T11:27:32.634380Z","shell.execute_reply.started":"2025-06-12T11:27:31.633379Z","shell.execute_reply":"2025-06-12T11:27:32.633788Z"}},"outputs":[{"name":"stdout","text":"âœ… MÃ£ lá»›p dá»± Ä‘oÃ¡n: 4\n","output_type":"stream"}],"execution_count":28}]}