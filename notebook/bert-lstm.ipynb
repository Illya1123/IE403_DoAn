{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12008326,"sourceType":"datasetVersion","datasetId":7554561}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers torch scikit-learn pandas","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T13:20:22.587152Z","iopub.execute_input":"2025-06-12T13:20:22.587310Z","iopub.status.idle":"2025-06-12T13:21:38.165568Z","shell.execute_reply.started":"2025-06-12T13:20:22.587295Z","shell.execute_reply":"2025-06-12T13:21:38.164862Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom transformers import BertTokenizer, BertModel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm import tqdm\n\n# Cáº¥u hÃ¬nh thiáº¿t bá»‹\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T13:21:38.166475Z","iopub.execute_input":"2025-06-12T13:21:38.166662Z","iopub.status.idle":"2025-06-12T13:22:02.958352Z","shell.execute_reply.started":"2025-06-12T13:21:38.166642Z","shell.execute_reply":"2025-06-12T13:22:02.957583Z"}},"outputs":[{"name":"stderr","text":"2025-06-12 13:21:51.575231: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749734511.776438      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749734511.835695      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/tiktok-comments/tiktok_comments_balanced.csv\")\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T13:22:02.960105Z","iopub.execute_input":"2025-06-12T13:22:02.960589Z","iopub.status.idle":"2025-06-12T13:22:03.029695Z","shell.execute_reply.started":"2025-06-12T13:22:02.960570Z","shell.execute_reply":"2025-06-12T13:22:03.029079Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   line_number                                               text  \\\n0         2679                                            sá»£ tháº­t   \n1        26129               á»‘i dá»“i Ã´i fpt shop chÃ¡y tá»›i Ä‘Ã³ má»‡t_Ã¡   \n2        20113                       xem mÃ  khÃ³c thÆ°Æ¡ng_k chá»‹u dc   \n3        17380               Ä‘Ã n_bÃ  sá»‘ng thá» hÆ¡n Ä‘Ã n_Ã´ng lÃ  váº­y k   \n4        18200  cÃ´ áº¥y giÃ  Ä‘i nhiá»u quÃ¡ váº«n nhá»› áº£nh chá»¥p cÃ´ lÃºc...   \n\n   emotion_label  \n0              3  \n1              2  \n2              2  \n3              0  \n4              2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>line_number</th>\n      <th>text</th>\n      <th>emotion_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2679</td>\n      <td>sá»£ tháº­t</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>26129</td>\n      <td>á»‘i dá»“i Ã´i fpt shop chÃ¡y tá»›i Ä‘Ã³ má»‡t_Ã¡</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20113</td>\n      <td>xem mÃ  khÃ³c thÆ°Æ¡ng_k chá»‹u dc</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17380</td>\n      <td>Ä‘Ã n_bÃ  sá»‘ng thá» hÆ¡n Ä‘Ã n_Ã´ng lÃ  váº­y k</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18200</td>\n      <td>cÃ´ áº¥y giÃ  Ä‘i nhiá»u quÃ¡ váº«n nhá»› áº£nh chá»¥p cÃ´ lÃºc...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"label_mapping = {\n    0: \"Vui váº»\",        # tÃ­ch cá»±c\n    1: \"Tá»©c giáº­n\",      # negative (giáº­n dá»¯, bá»±c tá»©c)\n    2: \"Buá»“n\",          # sadness\n    3: \"Sá»£ hÃ£i\",        # lo láº¯ng, hoáº£ng loáº¡n\n    4: \"Trung láº­p\"      # neutral\n}\ndf[\"label_text\"] = df[\"emotion_label\"].map(label_mapping)\n\nle = LabelEncoder()\ndf['label'] = le.fit_transform(df['label_text'])\nnum_classes = len(le.classes_)\n\n\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T13:22:03.030229Z","iopub.execute_input":"2025-06-12T13:22:03.030436Z","iopub.status.idle":"2025-06-12T13:22:03.054031Z","shell.execute_reply.started":"2025-06-12T13:22:03.030420Z","shell.execute_reply":"2025-06-12T13:22:03.053501Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"       line_number                                               text  \\\n0             2679                                            sá»£ tháº­t   \n1            26129               á»‘i dá»“i Ã´i fpt shop chÃ¡y tá»›i Ä‘Ã³ má»‡t_Ã¡   \n2            20113                       xem mÃ  khÃ³c thÆ°Æ¡ng_k chá»‹u dc   \n3            17380               Ä‘Ã n_bÃ  sá»‘ng thá» hÆ¡n Ä‘Ã n_Ã´ng lÃ  váº­y k   \n4            18200  cÃ´ áº¥y giÃ  Ä‘i nhiá»u quÃ¡ váº«n nhá»› áº£nh chá»¥p cÃ´ lÃºc...   \n...            ...                                                ...   \n14448        26549                                        nhÃ¬n sá»£ tháº¿   \n14449        19664                          khá»• thÃ¢n hai nhÃ  bÃªn cáº¡nh   \n14450        27967                                      hÃ£i lun vk Æ¡i   \n14451         7682                                                 vÅ©   \n14452         6513                         tá»±_hÃ o lÃ  ngÆ°á»i_dÃ¢n cá»§ chi   \n\n       emotion_label label_text  label  \n0                  3     Sá»£ hÃ£i      1  \n1                  2       Buá»“n      0  \n2                  2       Buá»“n      0  \n3                  0     Vui váº»      4  \n4                  2       Buá»“n      0  \n...              ...        ...    ...  \n14448              3     Sá»£ hÃ£i      1  \n14449              2       Buá»“n      0  \n14450              3     Sá»£ hÃ£i      1  \n14451              4  Trung láº­p      2  \n14452              0     Vui váº»      4  \n\n[14453 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>line_number</th>\n      <th>text</th>\n      <th>emotion_label</th>\n      <th>label_text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2679</td>\n      <td>sá»£ tháº­t</td>\n      <td>3</td>\n      <td>Sá»£ hÃ£i</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>26129</td>\n      <td>á»‘i dá»“i Ã´i fpt shop chÃ¡y tá»›i Ä‘Ã³ má»‡t_Ã¡</td>\n      <td>2</td>\n      <td>Buá»“n</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20113</td>\n      <td>xem mÃ  khÃ³c thÆ°Æ¡ng_k chá»‹u dc</td>\n      <td>2</td>\n      <td>Buá»“n</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17380</td>\n      <td>Ä‘Ã n_bÃ  sá»‘ng thá» hÆ¡n Ä‘Ã n_Ã´ng lÃ  váº­y k</td>\n      <td>0</td>\n      <td>Vui váº»</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18200</td>\n      <td>cÃ´ áº¥y giÃ  Ä‘i nhiá»u quÃ¡ váº«n nhá»› áº£nh chá»¥p cÃ´ lÃºc...</td>\n      <td>2</td>\n      <td>Buá»“n</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14448</th>\n      <td>26549</td>\n      <td>nhÃ¬n sá»£ tháº¿</td>\n      <td>3</td>\n      <td>Sá»£ hÃ£i</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14449</th>\n      <td>19664</td>\n      <td>khá»• thÃ¢n hai nhÃ  bÃªn cáº¡nh</td>\n      <td>2</td>\n      <td>Buá»“n</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14450</th>\n      <td>27967</td>\n      <td>hÃ£i lun vk Æ¡i</td>\n      <td>3</td>\n      <td>Sá»£ hÃ£i</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14451</th>\n      <td>7682</td>\n      <td>vÅ©</td>\n      <td>4</td>\n      <td>Trung láº­p</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>14452</th>\n      <td>6513</td>\n      <td>tá»±_hÃ o lÃ  ngÆ°á»i_dÃ¢n cá»§ chi</td>\n      <td>0</td>\n      <td>Vui váº»</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>14453 rows Ã— 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Chia dá»¯ liá»‡u\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    df['text'], df['label'], test_size=0.2, stratify=df['label'], random_state=42\n)\n\n# Tokenizer\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\nMAX_LEN = 64\n\ndef tokenize(texts):\n    input_ids, attention_masks = [], []\n    for text in texts:\n        encoded = tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=MAX_LEN,\n            truncation=True,\n            padding='max_length',\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n        input_ids.append(encoded['input_ids'])\n        attention_masks.append(encoded['attention_mask'])\n    return torch.cat(input_ids, dim=0), torch.cat(attention_masks, dim=0)\n\n# Token hÃ³a\ntrain_ids, train_masks = tokenize(train_texts.tolist())\nval_ids, val_masks = tokenize(val_texts.tolist())\n\ntrain_labels = torch.tensor(train_labels.tolist())\nval_labels = torch.tensor(val_labels.tolist())\n\n# DataLoader\ntrain_data = TensorDataset(train_ids, train_masks, train_labels)\nval_data = TensorDataset(val_ids, val_masks, val_labels)\n\ntrain_loader = DataLoader(train_data, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T13:22:03.054838Z","iopub.execute_input":"2025-06-12T13:22:03.055108Z","iopub.status.idle":"2025-06-12T13:22:10.934348Z","shell.execute_reply.started":"2025-06-12T13:22:03.055079Z","shell.execute_reply":"2025-06-12T13:22:10.933562Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"928ada10cdef456291f784a5a78cd9a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4137de46c6942459a6ca8c860fee1d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"086c697c380c47a2a12603d2eba85310"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7803ec61aaf4f1ca72df133b296c653"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Load BERT vÃ  LSTM\n\nclass BertLSTMClassifier(nn.Module):\n    def __init__(self, num_classes):\n        super(BertLSTMClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n        self.lstm = nn.LSTM(input_size=768, hidden_size=128, num_layers=1,\n                            batch_first=True, bidirectional=True)\n        self.dropout = nn.Dropout(0.3)\n        self.fc = nn.Linear(128 * 2, num_classes)\n\n    def forward(self, input_ids, attention_mask):\n        with torch.no_grad():\n            bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        lstm_out, _ = self.lstm(bert_output.last_hidden_state)\n        final_output = lstm_out[:, -1, :]\n        dropped = self.dropout(final_output)\n        logits = self.fc(dropped)\n        return logits\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T13:22:10.935172Z","iopub.execute_input":"2025-06-12T13:22:10.935405Z","iopub.status.idle":"2025-06-12T13:22:10.940986Z","shell.execute_reply.started":"2025-06-12T13:22:10.935387Z","shell.execute_reply":"2025-06-12T13:22:10.940350Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Huáº¥n luyá»‡n\nmodel = BertLSTMClassifier(num_classes).to(device)\noptimizer = optim.Adam(model.parameters(), lr=2e-4)\ncriterion = nn.CrossEntropyLoss()\n\nEPOCHS = 10\nfor epoch in range(EPOCHS):\n    model.train()\n    total_loss = 0\n\n    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n\n        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n        loss = criterion(logits, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    avg_loss = total_loss / len(train_loader)\n    print(f\"ğŸ“ˆ Epoch {epoch+1}/{EPOCHS} - Loss: {avg_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T13:28:04.481136Z","iopub.execute_input":"2025-06-12T13:28:04.481483Z","iopub.status.idle":"2025-06-12T13:36:27.542062Z","shell.execute_reply.started":"2025-06-12T13:28:04.481456Z","shell.execute_reply":"2025-06-12T13:36:27.541374Z"}},"outputs":[{"name":"stderr","text":"Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 362/362 [00:52<00:00,  6.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"ğŸ“ˆ Epoch 1/10 - Loss: 1.4124\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 362/362 [00:48<00:00,  7.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"ğŸ“ˆ Epoch 2/10 - Loss: 1.2836\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 362/362 [00:50<00:00,  7.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"ğŸ“ˆ Epoch 3/10 - Loss: 1.2413\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 362/362 [00:49<00:00,  7.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"ğŸ“ˆ Epoch 4/10 - Loss: 1.2222\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 362/362 [00:50<00:00,  7.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"ğŸ“ˆ Epoch 5/10 - Loss: 1.1937\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 362/362 [00:50<00:00,  7.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"ğŸ“ˆ Epoch 6/10 - Loss: 1.1795\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 362/362 [00:50<00:00,  7.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"ğŸ“ˆ Epoch 7/10 - Loss: 1.1586\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 362/362 [00:50<00:00,  7.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"ğŸ“ˆ Epoch 8/10 - Loss: 1.1354\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 362/362 [00:49<00:00,  7.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"ğŸ“ˆ Epoch 9/10 - Loss: 1.1322\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 362/362 [00:50<00:00,  7.24it/s]","output_type":"stream"},{"name":"stdout","text":"ğŸ“ˆ Epoch 10/10 - Loss: 1.1021\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"**ÄÃ¡nh giÃ¡**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport numpy as np\n\nmodel.eval()  # dÃ¹ng model Ä‘Ã£ Ä‘á»‹nh nghÄ©a (BertLSTMClassifier)\n\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for batch in tqdm(val_loader, desc=\"ÄÃ¡nh giÃ¡\"):\n        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n\n        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n        preds = torch.argmax(logits, dim=1)\n\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n# ÄÃ¡nh giÃ¡\nacc = accuracy_score(all_labels, all_preds)\nprint(f\"\\nâœ… Accuracy: {acc:.4f}\\n\")\n\nprint(\"ğŸ“‹ Classification Report:\")\nprint(classification_report(\n    all_labels, \n    all_preds, \n    target_names=le.classes_.astype(str), \n    digits=4\n))\n\nprint(\"ğŸ“Š Confusion Matrix:\")\nprint(confusion_matrix(all_labels, all_preds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T13:50:02.780018Z","iopub.execute_input":"2025-06-12T13:50:02.780336Z","iopub.status.idle":"2025-06-12T13:50:14.262715Z","shell.execute_reply.started":"2025-06-12T13:50:02.780291Z","shell.execute_reply":"2025-06-12T13:50:14.262024Z"}},"outputs":[{"name":"stderr","text":"ÄÃ¡nh giÃ¡: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:11<00:00,  7.94it/s]","output_type":"stream"},{"name":"stdout","text":"\nâœ… Accuracy: 0.5434\n\nğŸ“‹ Classification Report:\n              precision    recall  f1-score   support\n\n        Buá»“n     0.5318    0.5479    0.5397       626\n      Sá»£ hÃ£i     0.7210    0.6661    0.6925       551\n   Trung láº­p     0.5420    0.5390    0.5405       551\n    Tá»©c giáº­n     0.5239    0.5205    0.5222       611\n      Vui váº»     0.4227    0.4457    0.4339       552\n\n    accuracy                         0.5434      2891\n   macro avg     0.5483    0.5438    0.5457      2891\nweighted avg     0.5473    0.5434    0.5451      2891\n\nğŸ“Š Confusion Matrix:\n[[343  28  70  92  93]\n [ 54 367  33  67  30]\n [ 48  31 297  56 119]\n [100  54  45 318  94]\n [100  29 103  74 246]]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"Test model","metadata":{}},{"cell_type":"code","source":"def predict_sentiment(texts):\n    if isinstance(texts, str):\n        texts = [texts]\n\n    # Token hÃ³a\n    encoded = tokenizer.batch_encode_plus(\n        texts,\n        add_special_tokens=True,\n        max_length=64,\n        truncation=True,\n        padding='max_length',\n        return_attention_mask=True,\n        return_tensors='pt'\n    )\n\n    input_ids = encoded['input_ids'].to(device)\n    attention_mask = encoded['attention_mask'].to(device)\n\n    # Dá»± Ä‘oÃ¡n\n    model.eval()\n    with torch.no_grad():\n        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n        preds = torch.argmax(logits, dim=1)\n\n    return le.inverse_transform(preds.cpu().numpy())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T13:54:09.406437Z","iopub.execute_input":"2025-06-12T13:54:09.407048Z","iopub.status.idle":"2025-06-12T13:54:09.412422Z","shell.execute_reply.started":"2025-06-12T13:54:09.407025Z","shell.execute_reply":"2025-06-12T13:54:09.411692Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"test_inputs = [\n    \"Tá»± nhiÃªn ra Ä‘Æ°á»ng cÃ¡i k Ä‘á»¥ng cháº¡m j ai cá»§ng sá»£ ngangğŸ˜‘\",\n    \"LÃºc Ä‘áº§u thÃ¬ \"\"TÃ¹ng BÃ² Ä‘Ã¢m, xong 1 lÃºc sau thÃ¬ \"\"vÃ o tÃ¹ nha\"\"ğŸ˜‚\",\n    \"báº¯t quÃ¡ nhanh ğŸ¥° CÃ´ng An Viá»‡t Nam mÃ¬nh quÃ¡ giá»i, xuáº¥t sáº¯c ğŸ¥°\"\n]\n\npredicted_labels = predict_sentiment(test_inputs)\n\nfor text, label in zip(test_inputs, predicted_labels):\n    print(f\"ğŸ“ \\\"{text}\\\" â†’ ğŸ’¬ Dá»± Ä‘oÃ¡n: {label}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T14:15:08.082537Z","iopub.execute_input":"2025-06-12T14:15:08.083146Z","iopub.status.idle":"2025-06-12T14:15:08.113115Z","shell.execute_reply.started":"2025-06-12T14:15:08.083122Z","shell.execute_reply":"2025-06-12T14:15:08.112558Z"}},"outputs":[{"name":"stdout","text":"ğŸ“ \"Tá»± nhiÃªn ra Ä‘Æ°á»ng cÃ¡i k Ä‘á»¥ng cháº¡m j ai cá»§ng sá»£ ngangğŸ˜‘\" â†’ ğŸ’¬ Dá»± Ä‘oÃ¡n: Sá»£ hÃ£i\nğŸ“ \"LÃºc Ä‘áº§u thÃ¬ TÃ¹ng BÃ² Ä‘Ã¢m, xong 1 lÃºc sau thÃ¬ vÃ o tÃ¹ nhağŸ˜‚\" â†’ ğŸ’¬ Dá»± Ä‘oÃ¡n: Tá»©c giáº­n\nğŸ“ \"báº¯t quÃ¡ nhanh ğŸ¥° CÃ´ng An Viá»‡t Nam mÃ¬nh quÃ¡ giá»i, xuáº¥t sáº¯c ğŸ¥°\" â†’ ğŸ’¬ Dá»± Ä‘oÃ¡n: Vui váº»\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import zipfile\ntorch.save(model, \"bert_lstm_full_model.pt\")\n\n\nwith zipfile.ZipFile(\"bert_lstm_model.zip\", \"w\") as zipf:\n    zipf.write(\"bert_lstm_full_model.pt\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T13:22:15.088404Z","iopub.status.idle":"2025-06-12T13:22:15.088646Z","shell.execute_reply.started":"2025-06-12T13:22:15.088531Z","shell.execute_reply":"2025-06-12T13:22:15.088543Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import BertTokenizer\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n\nmodel = torch.load(\"/kaggle/working/bert_lstm_full_model.pt\", map_location=device, weights_only=False)\nmodel.eval()\n\ntext = \"Tá»± nhiÃªn ra Ä‘Æ°á»ng cÃ¡i k Ä‘á»¥ng cháº¡m j ai cá»§ng sá»£ ngangğŸ˜‘\"\n\nencoded = tokenizer.encode_plus(\n    text,\n    add_special_tokens=True,\n    max_length=64,\n    truncation=True,\n    padding='max_length',\n    return_attention_mask=True,\n    return_tensors='pt'\n)\n\ninput_ids = encoded['input_ids'].to(device)\nattention_mask = encoded['attention_mask'].to(device)\n\n\nwith torch.no_grad():\n    logits = model(input_ids, attention_mask)\n    pred = torch.argmax(logits, dim=1).item()\n\nprint(\"âœ… MÃ£ lá»›p dá»± Ä‘oÃ¡n:\", pred)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T13:22:15.089882Z","iopub.status.idle":"2025-06-12T13:22:15.090121Z","shell.execute_reply.started":"2025-06-12T13:22:15.090005Z","shell.execute_reply":"2025-06-12T13:22:15.090017Z"}},"outputs":[],"execution_count":null}]}