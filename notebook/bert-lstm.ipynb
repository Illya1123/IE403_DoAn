{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12008326,"sourceType":"datasetVersion","datasetId":7554561}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers torch scikit-learn pandas","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T10:44:10.448438Z","iopub.execute_input":"2025-06-12T10:44:10.448742Z","iopub.status.idle":"2025-06-12T10:45:23.891384Z","shell.execute_reply.started":"2025-06-12T10:44:10.448718Z","shell.execute_reply":"2025-06-12T10:45:23.890667Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom transformers import BertTokenizer, BertModel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm import tqdm\n\n# Cấu hình thiết bị\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T10:45:23.893011Z","iopub.execute_input":"2025-06-12T10:45:23.893245Z","iopub.status.idle":"2025-06-12T10:45:47.957342Z","shell.execute_reply.started":"2025-06-12T10:45:23.893222Z","shell.execute_reply":"2025-06-12T10:45:47.956565Z"}},"outputs":[{"name":"stderr","text":"2025-06-12 10:45:35.461519: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749725135.678024      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749725135.743980      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/tiktok-comments/tiktok_comments_balanced.csv\")\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T10:45:47.958201Z","iopub.execute_input":"2025-06-12T10:45:47.958804Z","iopub.status.idle":"2025-06-12T10:45:48.024568Z","shell.execute_reply.started":"2025-06-12T10:45:47.958780Z","shell.execute_reply":"2025-06-12T10:45:48.023943Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   line_number                                               text  \\\n0         2679                                            sợ thật   \n1        26129               ối dồi ôi fpt shop cháy tới đó mệt_á   \n2        20113                       xem mà khóc thương_k chịu dc   \n3        17380               đàn_bà sống thọ hơn đàn_ông là vậy k   \n4        18200  cô ấy già đi nhiều quá vẫn nhớ ảnh chụp cô lúc...   \n\n   emotion_label  \n0              3  \n1              2  \n2              2  \n3              0  \n4              2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>line_number</th>\n      <th>text</th>\n      <th>emotion_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2679</td>\n      <td>sợ thật</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>26129</td>\n      <td>ối dồi ôi fpt shop cháy tới đó mệt_á</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20113</td>\n      <td>xem mà khóc thương_k chịu dc</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17380</td>\n      <td>đàn_bà sống thọ hơn đàn_ông là vậy k</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18200</td>\n      <td>cô ấy già đi nhiều quá vẫn nhớ ảnh chụp cô lúc...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"label_mapping = {\n    0: \"Vui vẻ\",        # tích cực\n    1: \"Tức giận\",      # negative (giận dữ, bực tức)\n    2: \"Buồn\",          # sadness\n    3: \"Sợ hãi\",        # lo lắng, hoảng loạn\n    4: \"Trung lập\"      # neutral\n}\ndf[\"label_text\"] = df[\"emotion_label\"].map(label_mapping)\n\nle = LabelEncoder()\ndf['label'] = le.fit_transform(df['label_text'])\nnum_classes = len(le.classes_)\n\n\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T10:45:48.025943Z","iopub.execute_input":"2025-06-12T10:45:48.026133Z","iopub.status.idle":"2025-06-12T10:45:48.049739Z","shell.execute_reply.started":"2025-06-12T10:45:48.026119Z","shell.execute_reply":"2025-06-12T10:45:48.049196Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"       line_number                                               text  \\\n0             2679                                            sợ thật   \n1            26129               ối dồi ôi fpt shop cháy tới đó mệt_á   \n2            20113                       xem mà khóc thương_k chịu dc   \n3            17380               đàn_bà sống thọ hơn đàn_ông là vậy k   \n4            18200  cô ấy già đi nhiều quá vẫn nhớ ảnh chụp cô lúc...   \n...            ...                                                ...   \n14448        26549                                        nhìn sợ thế   \n14449        19664                          khổ thân hai nhà bên cạnh   \n14450        27967                                      hãi lun vk ơi   \n14451         7682                                                 vũ   \n14452         6513                         tự_hào là người_dân củ chi   \n\n       emotion_label label_text  label  \n0                  3     Sợ hãi      1  \n1                  2       Buồn      0  \n2                  2       Buồn      0  \n3                  0     Vui vẻ      4  \n4                  2       Buồn      0  \n...              ...        ...    ...  \n14448              3     Sợ hãi      1  \n14449              2       Buồn      0  \n14450              3     Sợ hãi      1  \n14451              4  Trung lập      2  \n14452              0     Vui vẻ      4  \n\n[14453 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>line_number</th>\n      <th>text</th>\n      <th>emotion_label</th>\n      <th>label_text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2679</td>\n      <td>sợ thật</td>\n      <td>3</td>\n      <td>Sợ hãi</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>26129</td>\n      <td>ối dồi ôi fpt shop cháy tới đó mệt_á</td>\n      <td>2</td>\n      <td>Buồn</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20113</td>\n      <td>xem mà khóc thương_k chịu dc</td>\n      <td>2</td>\n      <td>Buồn</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17380</td>\n      <td>đàn_bà sống thọ hơn đàn_ông là vậy k</td>\n      <td>0</td>\n      <td>Vui vẻ</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18200</td>\n      <td>cô ấy già đi nhiều quá vẫn nhớ ảnh chụp cô lúc...</td>\n      <td>2</td>\n      <td>Buồn</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14448</th>\n      <td>26549</td>\n      <td>nhìn sợ thế</td>\n      <td>3</td>\n      <td>Sợ hãi</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14449</th>\n      <td>19664</td>\n      <td>khổ thân hai nhà bên cạnh</td>\n      <td>2</td>\n      <td>Buồn</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14450</th>\n      <td>27967</td>\n      <td>hãi lun vk ơi</td>\n      <td>3</td>\n      <td>Sợ hãi</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14451</th>\n      <td>7682</td>\n      <td>vũ</td>\n      <td>4</td>\n      <td>Trung lập</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>14452</th>\n      <td>6513</td>\n      <td>tự_hào là người_dân củ chi</td>\n      <td>0</td>\n      <td>Vui vẻ</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>14453 rows × 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Chia dữ liệu\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    df['text'], df['label'], test_size=0.2, stratify=df['label'], random_state=42\n)\n\n# Tokenizer\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\nMAX_LEN = 64\n\ndef tokenize(texts):\n    input_ids, attention_masks = [], []\n    for text in texts:\n        encoded = tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=MAX_LEN,\n            truncation=True,\n            padding='max_length',\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n        input_ids.append(encoded['input_ids'])\n        attention_masks.append(encoded['attention_mask'])\n    return torch.cat(input_ids, dim=0), torch.cat(attention_masks, dim=0)\n\n# Token hóa\ntrain_ids, train_masks = tokenize(train_texts.tolist())\nval_ids, val_masks = tokenize(val_texts.tolist())\n\ntrain_labels = torch.tensor(train_labels.tolist())\nval_labels = torch.tensor(val_labels.tolist())\n\n# DataLoader\ntrain_data = TensorDataset(train_ids, train_masks, train_labels)\nval_data = TensorDataset(val_ids, val_masks, val_labels)\n\ntrain_loader = DataLoader(train_data, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T10:45:48.050458Z","iopub.execute_input":"2025-06-12T10:45:48.050747Z","iopub.status.idle":"2025-06-12T10:45:53.176039Z","shell.execute_reply.started":"2025-06-12T10:45:48.050724Z","shell.execute_reply":"2025-06-12T10:45:53.175288Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bea26dd8e324f518018b7b09bc48f6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"572a4e0dbb9a4286a40464f77a44ee82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54ba8908ae4c447bafd4343dc837133c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"581dba0b61ad4c46888365ff6f831bd7"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Load BERT và LSTM\n\nclass BertLSTMClassifier(nn.Module):\n    def __init__(self, num_classes):\n        super(BertLSTMClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n        self.lstm = nn.LSTM(input_size=768, hidden_size=128, num_layers=1,\n                            batch_first=True, bidirectional=True)\n        self.dropout = nn.Dropout(0.3)\n        self.fc = nn.Linear(128 * 2, num_classes)\n\n    def forward(self, input_ids, attention_mask):\n        with torch.no_grad():\n            bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        lstm_out, _ = self.lstm(bert_output.last_hidden_state)\n        final_output = lstm_out[:, -1, :]\n        dropped = self.dropout(final_output)\n        logits = self.fc(dropped)\n        return logits\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T11:08:24.020143Z","iopub.execute_input":"2025-06-12T11:08:24.020501Z","iopub.status.idle":"2025-06-12T11:08:24.026223Z","shell.execute_reply.started":"2025-06-12T11:08:24.020478Z","shell.execute_reply":"2025-06-12T11:08:24.025600Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Huấn luyện\nmodel = BertLSTMClassifier(num_classes).to(device)\noptimizer = optim.Adam(model.parameters(), lr=2e-4)\ncriterion = nn.CrossEntropyLoss()\n\nEPOCHS = 10\nfor epoch in range(EPOCHS):\n    lstm.train()\n    fc.train()\n    total_loss = 0\n\n    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n\n        with torch.no_grad():\n            bert_output = bert(input_ids=input_ids, attention_mask=attention_mask)\n        sequence_output = bert_output.last_hidden_state  # (B, T, 768)\n\n        lstm_out, _ = lstm(sequence_output)\n        final_output = lstm_out[:, -1, :]\n        dropped = dropout(final_output)\n        logits = fc(dropped)\n\n        loss = criterion(logits, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch+1} - Loss: {total_loss/len(train_loader):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T11:08:27.695640Z","iopub.execute_input":"2025-06-12T11:08:27.696174Z","iopub.status.idle":"2025-06-12T11:15:49.128745Z","shell.execute_reply.started":"2025-06-12T11:08:27.696153Z","shell.execute_reply":"2025-06-12T11:15:49.127788Z"}},"outputs":[{"name":"stderr","text":"Epoch 1: 100%|██████████| 362/362 [00:38<00:00,  9.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 - Loss: 0.6511\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 362/362 [00:40<00:00,  8.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 - Loss: 0.6510\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 362/362 [00:42<00:00,  8.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 - Loss: 0.6524\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 362/362 [00:44<00:00,  8.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 - Loss: 0.6532\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 362/362 [00:45<00:00,  7.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 - Loss: 0.6515\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 362/362 [00:45<00:00,  7.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 - Loss: 0.6520\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 362/362 [00:45<00:00,  7.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 - Loss: 0.6508\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|██████████| 362/362 [00:46<00:00,  7.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 - Loss: 0.6522\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|██████████| 362/362 [00:46<00:00,  7.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 - Loss: 0.6497\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10: 100%|██████████| 362/362 [00:46<00:00,  7.85it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 10 - Loss: 0.6521\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"**Đánh giá**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport numpy as np\n\nlstm.eval()\nfc.eval()\n\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for batch in tqdm(val_loader, desc=\"Đánh giá\"):\n        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n\n        bert_output = bert(input_ids=input_ids, attention_mask=attention_mask)\n        sequence_output = bert_output.last_hidden_state\n\n        lstm_out, _ = lstm(sequence_output)\n        final_output = lstm_out[:, -1, :]\n        logits = fc(dropout(final_output))\n\n        preds = torch.argmax(logits, dim=1)\n\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n# Đánh giá\nacc = accuracy_score(all_labels, all_preds)\nprint(f\"\\n✅ Accuracy: {acc:.4f}\\n\")\n\nprint(\"📋 Classification Report:\")\nprint(classification_report(all_labels, all_preds, target_names=le.classes_.astype(str)))\n\n# (Tuỳ chọn) Confusion Matrix\nprint(\"📊 Confusion Matrix:\")\nprint(confusion_matrix(all_labels, all_preds))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T11:17:39.241280Z","iopub.execute_input":"2025-06-12T11:17:39.241585Z","iopub.status.idle":"2025-06-12T11:17:48.929231Z","shell.execute_reply.started":"2025-06-12T11:17:39.241566Z","shell.execute_reply":"2025-06-12T11:17:48.928363Z"}},"outputs":[{"name":"stderr","text":"Đánh giá: 100%|██████████| 91/91 [00:09<00:00,  9.41it/s]","output_type":"stream"},{"name":"stdout","text":"\n✅ Accuracy: 0.5507\n\n📋 Classification Report:\n              precision    recall  f1-score   support\n\n        Buồn       0.59      0.51      0.54       626\n      Sợ hãi       0.65      0.70      0.67       551\n   Trung lập       0.57      0.54      0.55       551\n    Tức giận       0.50      0.59      0.54       611\n      Vui vẻ       0.45      0.42      0.43       552\n\n    accuracy                           0.55      2891\n   macro avg       0.55      0.55      0.55      2891\nweighted avg       0.55      0.55      0.55      2891\n\n📊 Confusion Matrix:\n[[318  56  63 116  73]\n [ 38 387  26  78  22]\n [ 49  35 296  67 104]\n [ 58  71  38 361  83]\n [ 80  49  96  97 230]]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"Test model","metadata":{}},{"cell_type":"code","source":"def predict_sentiment(texts):\n    if isinstance(texts, str):\n        texts = [texts]\n\n    # Token hóa\n    input_ids, attention_masks = tokenize(texts)\n    input_ids, attention_masks = input_ids.to(device), attention_masks.to(device)\n\n    # Trích đặc trưng từ BERT\n    with torch.no_grad():\n        bert_output = bert(input_ids=input_ids, attention_mask=attention_masks)\n        sequence_output = bert_output.last_hidden_state\n\n        lstm_out, _ = lstm(sequence_output)\n        final_output = lstm_out[:, -1, :]\n        logits = fc(dropout(final_output))\n        preds = torch.argmax(logits, dim=1)\n\n    return le.inverse_transform(preds.cpu().numpy())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T11:18:01.695070Z","iopub.execute_input":"2025-06-12T11:18:01.695381Z","iopub.status.idle":"2025-06-12T11:18:01.700706Z","shell.execute_reply.started":"2025-06-12T11:18:01.695359Z","shell.execute_reply":"2025-06-12T11:18:01.700129Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"test_inputs = [\n    \"Tự nhiên ra đường cái k đụng chạm j ai củng sợ ngang😑\",\n    \"Lúc đầu thì \"\"Tùng Bò đâm, xong 1 lúc sau thì \"\"vào tù nha\"\"😂\",\n    \"bắt quá nhanh 🥰 Công An Việt Nam mình quá giỏi, xuất sắc 🥰\"\n]\n\npredicted_labels = predict_sentiment(test_inputs)\n\nfor text, label in zip(test_inputs, predicted_labels):\n    print(f\"📝 \\\"{text}\\\" → 💬 Dự đoán: {label}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T11:18:04.474866Z","iopub.execute_input":"2025-06-12T11:18:04.475653Z","iopub.status.idle":"2025-06-12T11:18:04.503394Z","shell.execute_reply.started":"2025-06-12T11:18:04.475622Z","shell.execute_reply":"2025-06-12T11:18:04.502701Z"}},"outputs":[{"name":"stdout","text":"📝 \"Tự nhiên ra đường cái k đụng chạm j ai củng sợ ngang😑\" → 💬 Dự đoán: Sợ hãi\n📝 \"Lúc đầu thì Tùng Bò đâm, xong 1 lúc sau thì vào tù nha😂\" → 💬 Dự đoán: Vui vẻ\n📝 \"bắt quá nhanh 🥰 Công An Việt Nam mình quá giỏi, xuất sắc 🥰\" → 💬 Dự đoán: Vui vẻ\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import zipfile\ntorch.save(model, \"bert_lstm_full_model.pt\")\n\n\nwith zipfile.ZipFile(\"bert_lstm_model.zip\", \"w\") as zipf:\n    zipf.write(\"bert_lstm_full_model.pt\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T11:26:30.138672Z","iopub.execute_input":"2025-06-12T11:26:30.139403Z","iopub.status.idle":"2025-06-12T11:26:34.315626Z","shell.execute_reply.started":"2025-06-12T11:26:30.139374Z","shell.execute_reply":"2025-06-12T11:26:34.314731Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"from transformers import BertTokenizer\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n\nmodel = torch.load(\"/kaggle/working/bert_lstm_full_model.pt\", map_location=device, weights_only=False)\nmodel.eval()\n\ntext = \"Tự nhiên ra đường cái k đụng chạm j ai củng sợ ngang😑\"\n\nencoded = tokenizer.encode_plus(\n    text,\n    add_special_tokens=True,\n    max_length=64,\n    truncation=True,\n    padding='max_length',\n    return_attention_mask=True,\n    return_tensors='pt'\n)\n\ninput_ids = encoded['input_ids'].to(device)\nattention_mask = encoded['attention_mask'].to(device)\n\n\nwith torch.no_grad():\n    logits = model(input_ids, attention_mask)\n    pred = torch.argmax(logits, dim=1).item()\n\nprint(\"✅ Mã lớp dự đoán:\", pred)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T11:27:31.633087Z","iopub.execute_input":"2025-06-12T11:27:31.633406Z","iopub.status.idle":"2025-06-12T11:27:32.634380Z","shell.execute_reply.started":"2025-06-12T11:27:31.633379Z","shell.execute_reply":"2025-06-12T11:27:32.633788Z"}},"outputs":[{"name":"stdout","text":"✅ Mã lớp dự đoán: 4\n","output_type":"stream"}],"execution_count":28}]}