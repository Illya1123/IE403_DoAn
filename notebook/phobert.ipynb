{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11882251,"sourceType":"datasetVersion","datasetId":7467876}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"f67ac6d0-5fcb-4ae9-a674-27140fd85a40","cell_type":"code","source":"!pip install underthesea","metadata":{"execution":{"iopub.status.busy":"2025-05-21T08:07:09.008636Z","iopub.execute_input":"2025-05-21T08:07:09.008884Z","iopub.status.idle":"2025-05-21T08:07:14.850746Z","shell.execute_reply.started":"2025-05-21T08:07:09.008865Z","shell.execute_reply":"2025-05-21T08:07:14.849978Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting underthesea\n  Downloading underthesea-6.8.4-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.11/dist-packages (from underthesea) (8.1.8)\nCollecting python-crfsuite>=0.9.6 (from underthesea)\n  Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from underthesea) (3.9.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from underthesea) (4.67.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from underthesea) (2.32.3)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from underthesea) (1.5.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from underthesea) (1.2.2)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from underthesea) (6.0.2)\nCollecting underthesea-core==1.0.4 (from underthesea)\n  Downloading underthesea_core-1.0.4-cp311-cp311-manylinux2010_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->underthesea) (2024.11.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (2025.4.26)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea) (1.15.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn->underthesea) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn->underthesea) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn->underthesea) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn->underthesea) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn->underthesea) (2024.2.0)\nDownloading underthesea-6.8.4-py3-none-any.whl (20.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading underthesea_core-1.0.4-cp311-cp311-manylinux2010_x86_64.whl (657 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: underthesea-core, python-crfsuite, underthesea\nSuccessfully installed python-crfsuite-0.9.11 underthesea-6.8.4 underthesea-core-1.0.4\n","output_type":"stream"}],"execution_count":1},{"id":"54fbb94c","cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset, random_split\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom underthesea import word_tokenize, text_normalize\nimport os\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nfrom torch.optim import AdamW\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T08:07:14.852388Z","iopub.execute_input":"2025-05-21T08:07:14.852675Z","iopub.status.idle":"2025-05-21T08:07:28.045196Z","shell.execute_reply.started":"2025-05-21T08:07:14.852651Z","shell.execute_reply":"2025-05-21T08:07:28.044317Z"}},"outputs":[],"execution_count":2},{"id":"3e686abb","cell_type":"code","source":"stopword_path = '/kaggle/input/vietnamese-stopwords.txt'\ndata_path = '/kaggle/input/tiktok_comments_balanced.csv'\n\nwith open(stopword_path, 'r', encoding='utf-8') as f:\n    stopwords = set([line.strip() for line in f if line.strip()])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T08:07:28.046084Z","iopub.execute_input":"2025-05-21T08:07:28.046561Z","iopub.status.idle":"2025-05-21T08:07:28.063510Z","shell.execute_reply.started":"2025-05-21T08:07:28.046509Z","shell.execute_reply":"2025-05-21T08:07:28.062855Z"}},"outputs":[],"execution_count":3},{"id":"359a9497","cell_type":"code","source":"def preprocess_text(text):\n    text = text_normalize(text)\n    tokens = word_tokenize(text, format=\"text\").split()\n    tokens = [token for token in tokens if token.lower() not in stopwords]\n    return ' '.join(tokens)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T08:07:28.065591Z","iopub.execute_input":"2025-05-21T08:07:28.066160Z","iopub.status.idle":"2025-05-21T08:07:28.070179Z","shell.execute_reply.started":"2025-05-21T08:07:28.066141Z","shell.execute_reply":"2025-05-21T08:07:28.069590Z"}},"outputs":[],"execution_count":4},{"id":"242718cd","cell_type":"code","source":"comments=pd.read_csv('/kaggle/input/tiktok_comments_balanced.csv', usecols=['emotion_label', 'text'])\ncomments = comments.dropna(subset=['emotion_label'])\n\ncomments['emotion_label'] = comments['emotion_label'].astype(int)\nprint(comments.head())\n\nprint(f\"Sá»‘ lÆ°á»£ng comments: {comments.shape[0]}\")\nprint(f\"comments {type(comments['text'].tolist())}\")\nunique_emotions = np.sort(comments['emotion_label'].unique())\nprint(unique_emotions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T08:07:28.070886Z","iopub.execute_input":"2025-05-21T08:07:28.071208Z","iopub.status.idle":"2025-05-21T08:07:28.159036Z","shell.execute_reply.started":"2025-05-21T08:07:28.071182Z","shell.execute_reply":"2025-05-21T08:07:28.158404Z"}},"outputs":[{"name":"stdout","text":"                                                text  emotion_label\n0                                            sá»£ tháº­t              3\n1               á»‘i dá»“i Ã´i fpt shop chÃ¡y tá»›i Ä‘Ã³ má»‡t_Ã¡              2\n2                       xem mÃ  khÃ³c thÆ°Æ¡ng_k chá»‹u dc              2\n3               Ä‘Ã n_bÃ  sá»‘ng thá» hÆ¡n Ä‘Ã n_Ã´ng lÃ  váº­y k              0\n4  cÃ´ áº¥y giÃ  Ä‘i nhiá»u quÃ¡ váº«n nhá»› áº£nh chá»¥p cÃ´ lÃºc...              2\nSá»‘ lÆ°á»£ng comments: 14453\ncomments <class 'list'>\n[0 1 2 3 4]\n","output_type":"stream"}],"execution_count":5},{"id":"009c38cf","cell_type":"code","source":"model_name=\"vinai/phobert-base\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n\nnum_labels = 5\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T08:07:28.159891Z","iopub.execute_input":"2025-05-21T08:07:28.160181Z","iopub.status.idle":"2025-05-21T08:07:48.460500Z","shell.execute_reply.started":"2025-05-21T08:07:28.160162Z","shell.execute_reply":"2025-05-21T08:07:48.459723Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/557 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fe868151e5d4f81aa935b2100df86c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e930aab210143578de8417ca69bb704"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aff1df24d60244b6b3de830c687d4bd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/3.13M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"459c75ef7005421f854f2cd686b7d692"}},"metadata":{}},{"name":"stderr","text":"2025-05-21 08:07:31.749208: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747814851.968790      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747814852.027929      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/543M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf48416a5e36472897cfeeae36c765be"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":6},{"id":"465fe17b","cell_type":"code","source":"comments['text'] = comments['text'].astype(str)\ncomments['text'] = comments['text'].apply(preprocess_text)\nencoded_comments = tokenizer.batch_encode_plus(\n    comments['text'].tolist(),\n    add_special_tokens=True,\n    padding='max_length',\n    max_length=128,\n    truncation=True,\n    return_attention_mask=True,\n    return_tensors='pt'\n)\n\ninput_ids = encoded_comments['input_ids']\nattention_masks = encoded_comments['attention_mask']\nlabels = torch.tensor(comments['emotion_label'].values)\n\n\nprint(f\"attention_masks{attention_masks}\")\nprint(f\"labels{labels}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T08:07:48.461528Z","iopub.execute_input":"2025-05-21T08:07:48.462220Z","iopub.status.idle":"2025-05-21T08:07:58.657487Z","shell.execute_reply.started":"2025-05-21T08:07:48.462186Z","shell.execute_reply":"2025-05-21T08:07:58.656811Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/543M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72791292dbb44003b68513bea88c133d"}},"metadata":{}},{"name":"stdout","text":"attention_maskstensor([[1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        ...,\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0]])\nlabelstensor([3, 2, 2,  ..., 3, 4, 0])\n","output_type":"stream"}],"execution_count":7},{"id":"5371420a","cell_type":"code","source":"dataset = TensorDataset(input_ids, attention_masks, labels)\n\ntrain_size = int(0.9 * len(dataset))\nval_size = len(dataset) - train_size\n\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\nbatch_size = 16\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=0)\nprint(val_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T08:07:58.658260Z","iopub.execute_input":"2025-05-21T08:07:58.658726Z","iopub.status.idle":"2025-05-21T08:07:58.665921Z","shell.execute_reply.started":"2025-05-21T08:07:58.658704Z","shell.execute_reply":"2025-05-21T08:07:58.664962Z"}},"outputs":[{"name":"stdout","text":"<torch.utils.data.dataloader.DataLoader object at 0x7cd2c8d92f10>\n","output_type":"stream"}],"execution_count":8},{"id":"6a7bd0c4-65bd-4c51-9f27-89e1f24c253a","cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T08:07:58.666802Z","iopub.execute_input":"2025-05-21T08:07:58.667048Z","iopub.status.idle":"2025-05-21T08:07:58.992416Z","shell.execute_reply.started":"2025-05-21T08:07:58.667024Z","shell.execute_reply":"2025-05-21T08:07:58.991452Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n      (position_embeddings): Embedding(258, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=5, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":9},{"id":"a0a38056","cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=5e-5)\n\ntrain_losses = []\nval_accuracies = []\nval_losses = []\n\nmodel.train()\nnum_epochs = 1\n\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0\n    for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\", leave=False):\n        input_ids, attention_mask, labels = [x.to(model.device) for x in batch]\n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    avg_train_loss = total_loss / len(train_loader)\n    train_losses.append(avg_train_loss)\n\n    model.eval()\n    true_labels = []\n    pred_labels = []\n    val_loss = 0\n    with torch.no_grad():\n        for batch in tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}\", leave=False):\n            input_ids, attention_mask, labels = [x.to(model.device) for x in batch]\n            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n            val_loss += outputs.loss.item()\n\n            logits = outputs.logits\n            preds = torch.argmax(logits, axis=1)\n            pred_labels.extend(preds.cpu().numpy())\n            true_labels.extend(labels.cpu().numpy())\n\n    avg_val_loss = val_loss / len(val_loader)\n    val_losses.append(avg_val_loss)\n\n    accuracy = accuracy_score(true_labels, pred_labels)\n    val_accuracies.append(accuracy)\n\n    print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T08:07:58.997367Z","iopub.execute_input":"2025-05-21T08:07:58.997793Z","iopub.status.idle":"2025-05-21T08:10:52.576087Z","shell.execute_reply.started":"2025-05-21T08:07:58.997775Z","shell.execute_reply":"2025-05-21T08:10:52.575284Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Training Epoch 1:   0%|          | 0/813 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation Epoch 1:   0%|          | 0/91 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 1 | Train Loss: 1.1643 | Val Loss: 1.0239 | Val Accuracy: 0.6086\n","output_type":"stream"}],"execution_count":10},{"id":"c33dc39f","cell_type":"code","source":"model.eval()\n\ntrue_labels = []\npredictions = []\n\nwith torch.no_grad():  # No need to track gradients\n    for batch in tqdm(val_loader, desc=\"Evaluating\"):\n        input_ids, attention_mask, labels = batch\n        input_ids = input_ids.to(model.device)\n        attention_mask = attention_mask.to(model.device)\n        labels = labels.to(model.device)\n        \n        outputs = model(input_ids, attention_mask=attention_mask)\n        \n        logits = outputs.logits\n        pred_labels = torch.argmax(logits, axis=1)\n        \n        predictions.extend(pred_labels.cpu().numpy())\n        true_labels.extend(labels.cpu().numpy())\n\n# Calculate evaluation metrics\naccuracy = accuracy_score(true_labels, predictions)\nprecision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='macro')\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T08:10:52.577066Z","iopub.execute_input":"2025-05-21T08:10:52.577389Z","iopub.status.idle":"2025-05-21T08:10:57.633989Z","shell.execute_reply.started":"2025-05-21T08:10:52.577360Z","shell.execute_reply":"2025-05-21T08:10:57.633225Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/91 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f03c1bf55f64aaf8b0bd6a7c562b45f"}},"metadata":{}},{"name":"stdout","text":"Accuracy: 0.6086\nPrecision: 0.6060\nRecall: 0.6070\nF1 Score: 0.6016\n","output_type":"stream"}],"execution_count":11},{"id":"60316f19","cell_type":"code","source":"save_directory = '/kaggle/working/phobert-base'\nos.makedirs(save_directory, exist_ok=True)\n\nmodel.save_pretrained(save_directory)\ntokenizer.save_pretrained(save_directory)\n\nprint(f\"Model and tokenizer saved to {save_directory}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T08:10:57.635048Z","iopub.execute_input":"2025-05-21T08:10:57.635321Z","iopub.status.idle":"2025-05-21T08:10:58.866892Z","shell.execute_reply.started":"2025-05-21T08:10:57.635302Z","shell.execute_reply":"2025-05-21T08:10:58.866001Z"}},"outputs":[{"name":"stdout","text":"Model and tokenizer saved to /kaggle/working/phobert-base\n","output_type":"stream"}],"execution_count":12},{"id":"dad2696c","cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained('/kaggle/working/phobert-base')\ntokenizer = AutoTokenizer.from_pretrained('/kaggle/working/phobert-base')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T08:10:58.867816Z","iopub.execute_input":"2025-05-21T08:10:58.868073Z","iopub.status.idle":"2025-05-21T08:10:59.118500Z","shell.execute_reply.started":"2025-05-21T08:10:58.868054Z","shell.execute_reply":"2025-05-21T08:10:59.117877Z"}},"outputs":[],"execution_count":13},{"id":"c614fb7f","cell_type":"code","source":"torch.save({\n    'epoch': num_epochs,\n    'model_state_dict': model.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n    'loss': loss.item(),\n}, os.path.join(save_directory, 'training_checkpoint.pth'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T08:10:59.119202Z","iopub.execute_input":"2025-05-21T08:10:59.119411Z","iopub.status.idle":"2025-05-21T08:11:01.669698Z","shell.execute_reply.started":"2025-05-21T08:10:59.119396Z","shell.execute_reply":"2025-05-21T08:11:01.669062Z"}},"outputs":[],"execution_count":14},{"id":"7f749815","cell_type":"code","source":"checkpoint = torch.load('/kaggle/working/phobert-base/training_checkpoint.pth')\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\nstart_epoch = checkpoint['epoch']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T08:11:01.670841Z","iopub.execute_input":"2025-05-21T08:11:01.671087Z","iopub.status.idle":"2025-05-21T08:11:03.910362Z","shell.execute_reply.started":"2025-05-21T08:11:01.671059Z","shell.execute_reply":"2025-05-21T08:11:03.909485Z"}},"outputs":[],"execution_count":15},{"id":"4a52096d","cell_type":"code","source":"# Mapping label Ä‘á»ƒ hiá»ƒn thá»‹ dá»… hiá»ƒu (báº¡n chá»‰nh sá»­a náº¿u cáº§n)\nlabel_names = {\n    0: 'Vui váº»',\n    1: 'Tá»©c giáº­n',\n    2: 'Buá»“n bÃ£',\n    3: 'Sá»£ hÃ£i',\n    4: 'Trung láº­p'\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T08:11:03.911314Z","iopub.execute_input":"2025-05-21T08:11:03.911601Z","iopub.status.idle":"2025-05-21T08:11:03.916079Z","shell.execute_reply.started":"2025-05-21T08:11:03.911576Z","shell.execute_reply":"2025-05-21T08:11:03.915057Z"}},"outputs":[],"execution_count":16},{"id":"dbb3cb27","cell_type":"code","source":"print(\"\\n--- Examples of Predictions ---\")\nfor i in range(10):\n    pred = predictions[i]\n    true = true_labels[i]\n    text = comments.iloc[val_dataset.indices[i]]['text']\n    status = \"âœ… Correct\" if pred == true else \"âŒ Incorrect\"\n    print(f\"{status} | Text: {text}\\n  Predicted: {label_names[pred]}, Actual: {label_names[true]}\\n\")\n\ncorrect = [(p, t, comments.iloc[val_dataset.indices[i]]['text']) \n           for i, (p, t) in enumerate(zip(predictions, true_labels)) if p == t]\nincorrect = [(p, t, comments.iloc[val_dataset.indices[i]]['text']) \n             for i, (p, t) in enumerate(zip(predictions, true_labels)) if p != t]\n\nprint(f\"Tá»•ng sá»‘ Ä‘Ãºng: {len(correct)}\")\nprint(f\"Tá»•ng sá»‘ sai: {len(incorrect)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T08:11:03.916986Z","iopub.execute_input":"2025-05-21T08:11:03.917239Z","iopub.status.idle":"2025-05-21T08:11:03.989943Z","shell.execute_reply.started":"2025-05-21T08:11:03.917221Z","shell.execute_reply":"2025-05-21T08:11:03.989272Z"}},"outputs":[{"name":"stdout","text":"\n--- Examples of Predictions ---\nâœ… Correct | Text: tiktok\n  Predicted: Vui váº», Actual: Vui váº»\n\nâœ… Correct | Text: dÆ°Æ¡ng\n  Predicted: Trung láº­p, Actual: Trung láº­p\n\nâœ… Correct | Text: run máº¯c cÆ°á»i\n  Predicted: Sá»£ hÃ£i, Actual: Sá»£ hÃ£i\n\nâŒ Incorrect | Text: t rep m xui\n  Predicted: Buá»“n bÃ£, Actual: Tá»©c giáº­n\n\nâœ… Correct | Text: sá»£\n  Predicted: Sá»£ hÃ£i, Actual: Sá»£ hÃ£i\n\nâœ… Correct | Text: ghÃª\n  Predicted: Sá»£ hÃ£i, Actual: Sá»£ hÃ£i\n\nâœ… Correct | Text: vnpt xe cáº©u anh_hÃ¹ng\n  Predicted: Vui váº», Actual: Vui váº»\n\nâœ… Correct | Text: nam mÃ´_a di_Ä‘Ã  pháº­t\n  Predicted: Trung láº­p, Actual: Trung láº­p\n\nâœ… Correct | Text: sapa k ae\n  Predicted: Trung láº­p, Actual: Trung láº­p\n\nâœ… Correct | Text: eo sá»£ tháº¿_thua\n  Predicted: Sá»£ hÃ£i, Actual: Sá»£ hÃ£i\n\nTá»•ng sá»‘ Ä‘Ãºng: 880\nTá»•ng sá»‘ sai: 566\n","output_type":"stream"}],"execution_count":17},{"id":"bc5a58e0","cell_type":"code","source":"def predict_text(text):\n    model.eval()\n    text = preprocess_text(text)\n    encoded = tokenizer.encode_plus(\n        text,\n        add_special_tokens=True,\n        padding='max_length',\n        max_length=64,\n        truncation=True,\n        return_attention_mask=True,\n        return_tensors='pt'\n    )\n    input_ids = encoded['input_ids'].to(model.device)\n    attention_mask = encoded['attention_mask'].to(model.device)\n\n    with torch.no_grad():\n        outputs = model(input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        predicted_class = torch.argmax(logits, dim=1).item()\n\n    print(f\"\\nğŸ”® Dá»± Ä‘oÃ¡n cáº£m xÃºc: {label_names[predicted_class]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T08:11:03.990659Z","iopub.execute_input":"2025-05-21T08:11:03.990929Z","iopub.status.idle":"2025-05-21T08:11:03.996379Z","shell.execute_reply.started":"2025-05-21T08:11:03.990912Z","shell.execute_reply":"2025-05-21T08:11:03.995663Z"}},"outputs":[],"execution_count":18},{"id":"2334591d","cell_type":"code","source":"user_input = \"nghe báº¡n nam báº£o : khá»• tháº¿ nhá» Ä‘Ã£ dá»‹ch cÃ´ vÃ­t thÃ¬ chá»› mÃ  xÃ³tğŸ¥º\"\nprint(user_input)\npredict_text(user_input)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T08:11:03.997221Z","iopub.execute_input":"2025-05-21T08:11:03.997504Z","iopub.status.idle":"2025-05-21T08:11:04.240484Z","shell.execute_reply.started":"2025-05-21T08:11:03.997487Z","shell.execute_reply":"2025-05-21T08:11:04.239597Z"}},"outputs":[{"name":"stdout","text":"nghe báº¡n nam báº£o : khá»• tháº¿ nhá» Ä‘Ã£ dá»‹ch cÃ´ vÃ­t thÃ¬ chá»› mÃ  xÃ³tğŸ¥º\n\nğŸ”® Dá»± Ä‘oÃ¡n cáº£m xÃºc: Buá»“n bÃ£\n","output_type":"stream"}],"execution_count":19},{"id":"f1e96a6d-b4d8-4408-893a-8d3a6b5f583c","cell_type":"code","source":"!zip -r /kaggle/working/phobert-base.zip /kaggle/working/phobert-base\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T08:12:34.495960Z","iopub.execute_input":"2025-05-21T08:12:34.496743Z","iopub.status.idle":"2025-05-21T08:14:50.394790Z","shell.execute_reply.started":"2025-05-21T08:12:34.496716Z","shell.execute_reply":"2025-05-21T08:14:50.393741Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/phobert-base/ (stored 0%)\n  adding: kaggle/working/phobert-base/tokenizer_config.json (deflated 77%)\n  adding: kaggle/working/phobert-base/bpe.codes (deflated 59%)\n  adding: kaggle/working/phobert-base/model.safetensors (deflated 16%)\n  adding: kaggle/working/phobert-base/added_tokens.json (stored 0%)\n  adding: kaggle/working/phobert-base/config.json (deflated 54%)\n  adding: kaggle/working/phobert-base/special_tokens_map.json (deflated 57%)\n  adding: kaggle/working/phobert-base/training_checkpoint.pth (deflated 30%)\n  adding: kaggle/working/phobert-base/vocab.txt (deflated 55%)\n","output_type":"stream"}],"execution_count":20}]}